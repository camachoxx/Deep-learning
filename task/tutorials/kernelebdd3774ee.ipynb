{"cells":[{"metadata":{"id":"pZOW0AGeIm3d"},"cell_type":"markdown","source":"# how to use the task1 dataset tfrecords "},{"metadata":{"id":"YKZseevZIm3f"},"cell_type":"markdown","source":"Probably it will be necessary to train your model in 'Gogle Colaboratory' (colab) using the available GPU.\nSo we start with some instructions to can use your task1 dataset in colab."},{"metadata":{"id":"JfiPS2QDIm3h"},"cell_type":"markdown","source":"Use tensorflow 2"},{"metadata":{"id":"TFyBN0_Txn7n","outputId":"74560132-ab98-4175-899e-374f9236fc0e","trusted":true},"cell_type":"code","source":"import os\nimport tensorflow as tf\nimport numpy as np\nfrom tensorflow import keras\n#import IPython.display as display\n\nprint(tf.__version__)\n","execution_count":null,"outputs":[]},{"metadata":{"id":"Xw0oSmX1tBGM"},"cell_type":"markdown","source":"## Create tfrecords dataset"},{"metadata":{"id":"v9oZ-ahxIm4D"},"cell_type":"markdown","source":"**tf.data.Dataset** is tensorflow data input pipeline to used while training neural network models.\n**Tfrecords** are well integrated in the tf.data.Dataset framework."},{"metadata":{"id":"7zSfRxebt10C","trusted":true},"cell_type":"code","source":"tfrecordsDir = '../input/gray2Recs/'\ntrainNumbers = list(range(34))\nvalidNumbers = [34,36,37,38,39]\ntrainfiles = [tfrecordsDir + 'images_gray_'+str(i) + '.tfrecords' for i in trainNumbers]\nvalidfiles = [tfrecordsDir + 'images_gray_'+str(i) + '.tfrecords' for i in validNumbers]\n\ntrain_raw_image_dataset = tf.data.TFRecordDataset(trainfiles)\nvalid_raw_image_dataset = tf.data.TFRecordDataset(validfiles)","execution_count":null,"outputs":[]},{"metadata":{"id":"ulXPFvudIm4M"},"cell_type":"markdown","source":"How many examples are in the tfrecord"},{"metadata":{"id":"QYw03J9dtGmv","outputId":"71d54be2-6596-43ea-d187-aec14c158a42","trusted":true},"cell_type":"code","source":"count =0\nfor i in train_raw_image_dataset:\n  count +=1\nprint(count)","execution_count":null,"outputs":[]},{"metadata":{"id":"0ZRFhXH3tL9q"},"cell_type":"markdown","source":"## Decode tfrecords"},{"metadata":{"id":"Vvzc61OXt10I","trusted":true},"cell_type":"code","source":"# Create a dictionary describing the features.\nimage_feature_description = {\n            'chinaprov': tf.io.FixedLenFeature([], tf.int64),\n            'letter': tf.io.FixedLenFeature([], tf.int64),\n            'seq0':  tf.io.FixedLenFeature([], tf.int64),\n            'seq1': tf.io.FixedLenFeature([], tf.int64),\n            'seq2':  tf.io.FixedLenFeature([], tf.int64),\n            'seq3': tf.io.FixedLenFeature([], tf.int64),\n            'seq4':  tf.io.FixedLenFeature([], tf.int64),\n            'image_raw': tf.io.FixedLenFeature([], tf.string),\n        }\n","execution_count":null,"outputs":[]},{"metadata":{"id":"Uqjmu7tIt10N","trusted":true},"cell_type":"code","source":"def _parse_image_function(example_proto):\n  # Parse the input tf.Example proto using the dictionary above.\n  return tf.io.parse_single_example(example_proto, image_feature_description)\n","execution_count":null,"outputs":[]},{"metadata":{"id":"fVm-Izeb0-JM","trusted":true},"cell_type":"code","source":"train_parsed_image_dataset = train_raw_image_dataset.map(_parse_image_function)\nval_parsed_image_dataset = valid_raw_image_dataset.map(_parse_image_function)","execution_count":null,"outputs":[]},{"metadata":{"id":"Oj7HZnvqsZ_e"},"cell_type":"markdown","source":"### **look** at one example"},{"metadata":{"id":"mXU_dFJFdQtA","outputId":"969d857f-08ef-49f1-e6c8-61ffea1a9692","trusted":true},"cell_type":"code","source":"import IPython.display as display\nit = iter(train_parsed_image_dataset)\ndata_parsed =next(it)\nimage = data_parsed['image_raw'].numpy()\ndisplay.display(display.Image(data=image))\nimg = tf.image.decode_png(data_parsed['image_raw'])\nprint(img.numpy().shape)\nprint(img.numpy().dtype)","execution_count":null,"outputs":[]},{"metadata":{"id":"KsJzQvUTT3DE"},"cell_type":"markdown","source":" ## Create inputs and labels from raw images"},{"metadata":{"id":"7OUVwtkOfFz_","trusted":true},"cell_type":"code","source":"num_chinaprov = 34\nnum_letter = 34\nnum_seq = 34\n\n\n\ndef buildLabels(parsed_data):\n  chinaprov = parsed_data['chinaprov']\n  chinaprov_enc = tf.keras.backend.one_hot(chinaprov,num_chinaprov)\n  letter = parsed_data['letter']\n  letter_enc = tf.keras.backend.one_hot(letter, num_letter)\n  seq0 = parsed_data['seq0']\n  seq0_enc = tf.keras.backend.one_hot(seq0, num_seq)\n  seq1 = parsed_data['seq1']\n  seq1_enc = tf.keras.backend.one_hot(seq1, num_seq)\n  seq2 = parsed_data['seq2']\n  seq2_enc = tf.keras.backend.one_hot(seq2, num_seq)\n  seq3 = parsed_data['seq3']\n  seq3_enc = tf.keras.backend.one_hot(seq3, num_seq)\n  seq4  = parsed_data['seq4']\n  seq4_enc = tf.keras.backend.one_hot(seq4, num_seq)\n  label = tf.stack([chinaprov_enc, letter_enc, seq0_enc, seq1_enc, seq2_enc, seq3_enc, seq4_enc])\n  return label\n\n\n\ndef buildInputsLabels(parsed_data):\n  img = tf.image.decode_png(parsed_data['image_raw'])\n  img = tf.dtypes.cast(img, dtype = tf.float32)\n  labels = buildLabels(parsed_data)   \n  return   img,  labels","execution_count":null,"outputs":[]},{"metadata":{"id":"CDX6RnCPUekp","trusted":true},"cell_type":"code","source":"trainDataset = train_parsed_image_dataset.map(buildInputsLabels).shuffle(2000)\nvalDataset = val_parsed_image_dataset.map(buildInputsLabels).shuffle(2000)","execution_count":null,"outputs":[]},{"metadata":{"id":"At1aByO_U6aR"},"cell_type":"markdown","source":"### get one example, inputs, label from the dataset"},{"metadata":{"id":"yTC4SHaOt7oK","outputId":"ce282afb-43d3-41bb-b418-ef1833588339","trusted":true},"cell_type":"code","source":"newIt = iter(trainDataset)\ndata =next(newIt)\ndata[1].shape\n","execution_count":null,"outputs":[]},{"metadata":{"id":"mMjh0iWZDevi","trusted":true},"cell_type":"code","source":"import pandas as pd\nfrom tensorflow.keras.optimizers import SGD\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, BatchNormalization, Conv2D, Dense\nfrom tensorflow.keras.layers import MaxPooling2D, Activation, Flatten, Dropout\nfrom tensorflow.keras.layers import LeakyReLU, Reshape, Concatenate\nfrom tensorflow.keras import regularizers","execution_count":null,"outputs":[]},{"metadata":{"id":"l2i3OJRUjj8B","trusted":true},"cell_type":"code","source":"batchsize=33\nbatchDataset = trainDataset.batch(batchsize)\n\nvalbatch=33\nval_batch = valDataset.batch(valbatch)","execution_count":null,"outputs":[]},{"metadata":{"id":"M0nNvSs4kggn","trusted":true},"cell_type":"code","source":"output_nodes = data[1].shape[1]\nn_classes = data[1].shape[0]","execution_count":null,"outputs":[]},{"metadata":{"id":"nc2FIBEJWvhA","outputId":"8286f82d-8875-4498-c610-2c5dc9a07c9c","trusted":true},"cell_type":"code","source":"data[0].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inputs = Input(shape=data[0].shape,name='inputs')\n\nlayer=Conv2D(10, kernel_size=(9,9),data_format='channels_last',strides=2)(inputs)\nlayer=LeakyReLU(alpha=0.1)(layer)\nlayer=BatchNormalization()(layer)\nlayer=MaxPooling2D(pool_size=(2, 2),padding='same')(layer)\nlayer=Dropout(0.4)(layer)\n\nlayer=Conv2D(16, kernel_size=(9,9))(layer)\nlayer=LeakyReLU(alpha=0.1)(layer)\nlayer=BatchNormalization()(layer)\nlayer=MaxPooling2D(pool_size=(2, 2),padding='same')(layer)\nlayer1=Dropout(0.4)(layer)\n\nClayer1=Flatten()(layer1)\n\nlayer=Conv2D(32, kernel_size=(9, 9), padding='same')(layer1)\nlayer=LeakyReLU(alpha=0.1)(layer)\nlayer=BatchNormalization()(layer)\nlayer=MaxPooling2D(pool_size=(2, 2),padding='same')(layer)\nlayer=Dropout(0.4)(layer)\n\nlayer=Conv2D(64, kernel_size=(9, 9), padding='same')(layer)\nlayer=LeakyReLU(alpha=0.1)(layer)\nlayer=BatchNormalization()(layer)\nlayer=MaxPooling2D(pool_size=(2, 2),padding='same')(layer)\nlayer2=Dropout(0.4)(layer)\n\nClayer2=Flatten()(layer2)\n\nlayer=Conv2D(128, kernel_size=(9, 9), padding='same')(layer2)\nlayer=LeakyReLU(alpha=0.1)(layer)\nlayer=BatchNormalization()(layer)\nlayer=MaxPooling2D(pool_size=(2, 2),padding='same')(layer)\nlayer=Dropout(0.4)(layer)\n\nlayer=Conv2D(160, kernel_size=(9, 9), padding='same')(layer)\nlayer=LeakyReLU(alpha=0.1)(layer)\nlayer=BatchNormalization()(layer)\nlayer=MaxPooling2D(pool_size=(2, 2),padding='same')(layer)\nlayer3=Dropout(0.4)(layer)\n\nClayer3=Flatten()(layer3)\n\nlayer=Conv2D(190, kernel_size=(9, 9), padding='same')(layer3)\nlayer=LeakyReLU(alpha=0.1)(layer)\nlayer=BatchNormalization()(layer)\nlayer=MaxPooling2D(pool_size=(2, 2),padding='same')(layer)\nlayer=Dropout(0.4)(layer)\n\nlayer=Conv2D(220, kernel_size=(9, 9), padding='same')(layer)\nlayer=LeakyReLU(alpha=0.1)(layer)\nlayer=BatchNormalization()(layer)\nlayer=MaxPooling2D(pool_size=(2, 2),padding='same')(layer)\nlayer4=Dropout(0.4)(layer)\n\nClayer4=Flatten()(layer4)\n\n\nmerge=Concatenate()([Clayer1, Clayer2, Clayer3, Clayer4])\n\npredlayer=Flatten()(merge)\npredlayer=Dense(320)(predlayer)\npredlayer=LeakyReLU(alpha=0.1)(predlayer)\npredlayer=BatchNormalization()(predlayer)\npredlayer=Dropout(0.5)(predlayer)\n\npredlayer=Dense(280)(predlayer)\npredlayer=LeakyReLU(alpha=0.1)(predlayer)\npredlayer=BatchNormalization()(predlayer)\npredlayer=Dropout(0.5)(predlayer)\n\npredlayer=Dense(250)(predlayer)\npredlayer=LeakyReLU(alpha=0.1)(predlayer)\npredlayer=BatchNormalization()(predlayer)\npredlayer=Dropout(0.5)(predlayer)\n\noutput_layer    = Dense(7*34)(predlayer)\noutput_reshape  = Reshape((7,34))(output_layer)","execution_count":null,"outputs":[]},{"metadata":{"id":"4OpjoVEUNYcf","trusted":true},"cell_type":"code","source":"model = Model(inputs = inputs, outputs = output_reshape)","execution_count":null,"outputs":[]},{"metadata":{"id":"aAWFb79106HO","outputId":"3221a774-ace2-4718-fa5d-15c6f6f4c614","trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"id":"4zBkEgQM1DL-","trusted":true},"cell_type":"code","source":"def train(NUM_EPOCHS=30):\n  model.compile(loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True), optimizer=\"Adamax\", \n                  metrics=[\"accuracy\"])\n\n  H = model.fit(batchDataset,validation_data=(val_batch), epochs=NUM_EPOCHS)\n  return H\n\ndef predict(x):\n  return np.argmax(model.predict(x),axis=-1)\n\n\ndef predict_prob(x):\n  return model.predict(x)\n\ndef evaluate(x,y,batches=batchsize):\n  return model.evaluate(x,y)","execution_count":null,"outputs":[]},{"metadata":{"id":"eX7rpS2nPNQn","outputId":"8445eeb2-a7ca-4a2d-f5fb-2f4581379df5","trusted":true},"cell_type":"code","source":"history=train(35)","execution_count":null,"outputs":[]},{"metadata":{"id":"U9nRPIh_H6Pq","trusted":true},"cell_type":"code","source":"dic=history.history","execution_count":null,"outputs":[]},{"metadata":{"id":"YUVbf9rugNk-","trusted":true},"cell_type":"code","source":"# Save the model\nmodel.save('deep_model.h5')\n","execution_count":null,"outputs":[]},{"metadata":{"id":"Gy4b81iazh-s","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.style.use('seaborn-whitegrid')\nfrom matplotlib.pyplot import figure\n","execution_count":null,"outputs":[]},{"metadata":{"id":"JK2T4KzOzkTR","trusted":true},"cell_type":"code","source":"figure(num=None, figsize=(12, 7), dpi=80, facecolor='w', edgecolor='k')\nplt.plot(dic[\"accuracy\"]);\nplt.plot(dic[\"val_accuracy\"]);\nplt.savefig(\"/acc.png\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"figure(num=None, figsize=(12, 7), dpi=80, facecolor='w', edgecolor='k')\nplt.plot(dic[\"loss\"]);\nplt.plot(dic[\"val_loss\"]);\nplt.savefig(\"/loss.png\")","execution_count":null,"outputs":[]},{"metadata":{"id":"03O41uN_TWRK","trusted":true},"cell_type":"code","source":"newIt = iter(val_batch)\ndata =next(newIt)\ndata[0]","execution_count":null,"outputs":[]},{"metadata":{"id":"dRBfsQCmIm5B","trusted":true},"cell_type":"code","source":"predict(data[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.argmax(data[1].numpy(),axis=-1)","execution_count":null,"outputs":[]},{"metadata":{"id":"cVi9JP991gJK","trusted":true},"cell_type":"code","source":"evaluate(data[0],data[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"name":"inspectTfrecord2.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":4}