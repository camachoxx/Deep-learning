{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pZOW0AGeIm3d"
   },
   "source": [
    "# how to use the task1 dataset tfrecords "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YKZseevZIm3f"
   },
   "source": [
    "Probably it will be necessary to train your model in 'Gogle Colaboratory' (colab) using the available GPU.\n",
    "So we start with some instructions to can use your task1 dataset in colab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JfiPS2QDIm3h"
   },
   "source": [
    "Use tensorflow 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FdSmtD4ct1z3"
   },
   "outputs": [],
   "source": [
    "%tensorflow_version 2.x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "TFyBN0_Txn7n",
    "outputId": "9338340b-044f-42cb-8563-b54e7417860b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "#import IPython.display as display\n",
    "\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "96lXhPlPsx8k"
   },
   "source": [
    "## Import data from Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zEnfN6iAt6zT"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/google-drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xw0oSmX1tBGM"
   },
   "source": [
    "## Create tfrecords dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v9oZ-ahxIm4D"
   },
   "source": [
    "**tf.data.Dataset** is tensorflow data input pipeline to used while training neural network models.\n",
    "**Tfrecords** are well integrated in the tf.data.Dataset framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7zSfRxebt10C"
   },
   "outputs": [],
   "source": [
    "tfrecordsDir = '/content/google-drive/My Drive/gray2Recs/'\n",
    "trainNumbers = list(range(32))\n",
    "validNumbers = [32,33,34,35]\n",
    "trainfiles = [tfrecordsDir + 'images_gray_'+str(i) + '.tfrecords' for i in trainNumbers]\n",
    "validfiles = [tfrecordsDir + 'images_gray_'+str(i) + '.tfrecords' for i in validNumbers]\n",
    "\n",
    "train_raw_image_dataset = tf.data.TFRecordDataset(trainfiles)\n",
    "valid_raw_image_dataset = tf.data.TFRecordDataset(validfiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0ZRFhXH3tL9q"
   },
   "source": [
    "## Decode tfrecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vvzc61OXt10I"
   },
   "outputs": [],
   "source": [
    "# Create a dictionary describing the features.\n",
    "image_feature_description = {\n",
    "            'chinaprov': tf.io.FixedLenFeature([], tf.int64),\n",
    "            'letter': tf.io.FixedLenFeature([], tf.int64),\n",
    "            'seq0':  tf.io.FixedLenFeature([], tf.int64),\n",
    "            'seq1': tf.io.FixedLenFeature([], tf.int64),\n",
    "            'seq2':  tf.io.FixedLenFeature([], tf.int64),\n",
    "            'seq3': tf.io.FixedLenFeature([], tf.int64),\n",
    "            'seq4':  tf.io.FixedLenFeature([], tf.int64),\n",
    "            'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Uqjmu7tIt10N"
   },
   "outputs": [],
   "source": [
    "def _parse_image_function(example_proto):\n",
    "  # Parse the input tf.Example proto using the dictionary above.\n",
    "  return tf.io.parse_single_example(example_proto, image_feature_description)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fVm-Izeb0-JM"
   },
   "outputs": [],
   "source": [
    "train_parsed_image_dataset = train_raw_image_dataset.map(_parse_image_function)\n",
    "val_parsed_image_dataset = valid_raw_image_dataset.map(_parse_image_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Oj7HZnvqsZ_e"
   },
   "source": [
    "### **look** at one example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mXU_dFJFdQtA"
   },
   "outputs": [],
   "source": [
    "import IPython.display as display\n",
    "it = iter(train_parsed_image_dataset)\n",
    "data_parsed =next(it)\n",
    "image = data_parsed['image_raw'].numpy()\n",
    "display.display(display.Image(data=image))\n",
    "img = tf.image.decode_png(data_parsed['image_raw'])\n",
    "print(img.numpy().shape)\n",
    "print(img.numpy().dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KsJzQvUTT3DE"
   },
   "source": [
    " ## Create inputs and labels from raw images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7OUVwtkOfFz_"
   },
   "outputs": [],
   "source": [
    "num_chinaprov = 34\n",
    "num_letter = 34\n",
    "num_seq = 34\n",
    "\n",
    "\n",
    "\n",
    "def buildLabels(parsed_data):\n",
    "  chinaprov = parsed_data['chinaprov']\n",
    "  chinaprov_enc = tf.keras.backend.one_hot(chinaprov,num_chinaprov)\n",
    "  letter = parsed_data['letter']\n",
    "  letter_enc = tf.keras.backend.one_hot(letter, num_letter)\n",
    "  seq0 = parsed_data['seq0']\n",
    "  seq0_enc = tf.keras.backend.one_hot(seq0, num_seq)\n",
    "  seq1 = parsed_data['seq1']\n",
    "  seq1_enc = tf.keras.backend.one_hot(seq1, num_seq)\n",
    "  seq2 = parsed_data['seq2']\n",
    "  seq2_enc = tf.keras.backend.one_hot(seq2, num_seq)\n",
    "  seq3 = parsed_data['seq3']\n",
    "  seq3_enc = tf.keras.backend.one_hot(seq3, num_seq)\n",
    "  seq4  = parsed_data['seq4']\n",
    "  seq4_enc = tf.keras.backend.one_hot(seq4, num_seq)\n",
    "  label = tf.stack([chinaprov_enc, letter_enc, seq0_enc, seq1_enc, seq2_enc, seq3_enc, seq4_enc])\n",
    "  return label\n",
    "\n",
    "\n",
    "\n",
    "def buildInputsLabels(parsed_data):\n",
    "  img = tf.image.decode_png(parsed_data['image_raw'])\n",
    "  img = tf.dtypes.cast(img, dtype = tf.float32)\n",
    "  labels = buildLabels(parsed_data)   \n",
    "  return   img,  labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CDX6RnCPUekp"
   },
   "outputs": [],
   "source": [
    "trainDataset = train_parsed_image_dataset.map(buildInputsLabels).shuffle(2000)\n",
    "valDataset = val_parsed_image_dataset.map(buildInputsLabels).shuffle(2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "At1aByO_U6aR"
   },
   "source": [
    "### get one example, inputs, label from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yTC4SHaOt7oK"
   },
   "outputs": [],
   "source": [
    "newIt = iter(trainDataset)\n",
    "data =next(newIt)\n",
    "data[1].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mMjh0iWZDevi"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, BatchNormalization, Conv2D, Dense\n",
    "from tensorflow.keras.layers import MaxPooling2D, Activation, Flatten, Dropout\n",
    "from tensorflow.keras.layers import LeakyReLU, Reshape, Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l2i3OJRUjj8B"
   },
   "outputs": [],
   "source": [
    "batchsize=33\n",
    "batchDataset = trainDataset.batch(batchsize)\n",
    "\n",
    "valbatch=33\n",
    "val_batch = valDataset.batch(valbatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M0nNvSs4kggn"
   },
   "outputs": [],
   "source": [
    "output_nodes = data[1].shape[1]\n",
    "n_classes = data[1].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nc2FIBEJWvhA"
   },
   "outputs": [],
   "source": [
    "data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PYxAcRX_Db0G"
   },
   "outputs": [],
   "source": [
    "inputs = Input(shape=data[0].shape,name='inputs')\n",
    "\n",
    "layer=Conv2D(10, kernel_size=(9,9),data_format='channels_last',strides=2)(inputs)\n",
    "layer=LeakyReLU(alpha=0.1)(layer)\n",
    "layer=BatchNormalization()(layer)\n",
    "layer=MaxPooling2D(pool_size=(2, 2),padding='same')(layer)\n",
    "layer=Dropout(0.2)(layer)\n",
    "\n",
    "layer=Conv2D(16, kernel_size=(9,9))(layer)\n",
    "layer=LeakyReLU(alpha=0.1)(layer)\n",
    "layer=BatchNormalization()(layer)\n",
    "layer=MaxPooling2D(pool_size=(2, 2),padding='same')(layer)\n",
    "layer1=Dropout(0.2)(layer)\n",
    "\n",
    "Clayer1=Flatten()(layer1)\n",
    "\n",
    "layer=Conv2D(32, kernel_size=(9, 9), padding='same')(layer1)\n",
    "layer=LeakyReLU(alpha=0.1)(layer)\n",
    "layer=BatchNormalization()(layer)\n",
    "layer=MaxPooling2D(pool_size=(2, 2),padding='same')(layer)\n",
    "layer=Dropout(0.2)(layer)\n",
    "\n",
    "layer=Conv2D(64, kernel_size=(9, 9), padding='same')(layer)\n",
    "layer=LeakyReLU(alpha=0.1)(layer)\n",
    "layer=BatchNormalization()(layer)\n",
    "layer=MaxPooling2D(pool_size=(2, 2),padding='same')(layer)\n",
    "layer2=Dropout(0.2)(layer)\n",
    "\n",
    "Clayer2=Flatten()(layer2)\n",
    "\n",
    "layer=Conv2D(128, kernel_size=(9, 9), padding='same')(layer2)\n",
    "layer=LeakyReLU(alpha=0.1)(layer)\n",
    "layer=BatchNormalization()(layer)\n",
    "layer=MaxPooling2D(pool_size=(2, 2),padding='same')(layer)\n",
    "layer=Dropout(0.2)(layer)\n",
    "\n",
    "layer=Conv2D(160, kernel_size=(9, 9), padding='same')(layer)\n",
    "layer=LeakyReLU(alpha=0.1)(layer)\n",
    "layer=BatchNormalization()(layer)\n",
    "layer=MaxPooling2D(pool_size=(2, 2),padding='same')(layer)\n",
    "layer3=Dropout(0.2)(layer)\n",
    "\n",
    "Clayer3=Flatten()(layer3)\n",
    "\n",
    "layer=Conv2D(190, kernel_size=(9, 9), padding='same')(layer3)\n",
    "layer=LeakyReLU(alpha=0.1)(layer)\n",
    "layer=BatchNormalization()(layer)\n",
    "layer=MaxPooling2D(pool_size=(2, 2),padding='same')(layer)\n",
    "layer=Dropout(0.2)(layer)\n",
    "\n",
    "layer=Conv2D(220, kernel_size=(9, 9), padding='same')(layer)\n",
    "layer=LeakyReLU(alpha=0.1)(layer)\n",
    "layer=BatchNormalization()(layer)\n",
    "layer=MaxPooling2D(pool_size=(2, 2),padding='same')(layer)\n",
    "layer4=Dropout(0.2)(layer)\n",
    "\n",
    "Clayer4=Flatten()(layer4)\n",
    "\n",
    "\n",
    "merge=Concatenate()([Clayer1, Clayer2, Clayer3, Clayer4])\n",
    "\n",
    "predlayer=Flatten()(merge)\n",
    "predlayer=Dense(320)(predlayer)\n",
    "predlayer=LeakyReLU(alpha=0.1)(predlayer)\n",
    "predlayer=BatchNormalization()(predlayer)\n",
    "predlayer=Dropout(0.4)(predlayer)\n",
    "\n",
    "predlayer=Dense(280)(predlayer)\n",
    "predlayer=LeakyReLU(alpha=0.1)(predlayer)\n",
    "predlayer=BatchNormalization()(predlayer)\n",
    "predlayer=Dropout(0.4)(predlayer)\n",
    "\n",
    "predlayer=Dense(250)(predlayer)\n",
    "predlayer=LeakyReLU(alpha=0.1)(predlayer)\n",
    "predlayer=BatchNormalization()(predlayer)\n",
    "predlayer=Dropout(0.4)(predlayer)\n",
    "\n",
    "output_layer    = Dense(7*34)(predlayer)\n",
    "output_reshape  = Reshape((7,34))(output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4OpjoVEUNYcf"
   },
   "outputs": [],
   "source": [
    "model = Model(inputs = inputs, outputs = output_reshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aAWFb79106HO"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4zBkEgQM1DL-"
   },
   "outputs": [],
   "source": [
    "def train(NUM_EPOCHS=25):\n",
    "  model.compile(loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True), optimizer=\"Adamax\", \n",
    "                  metrics=[\"accuracy\"])\n",
    "\n",
    "  H = model.fit(batchDataset,validation_data=(val_batch), epochs=NUM_EPOCHS)\n",
    "  return H\n",
    "\n",
    "def predict(x):\n",
    "  return np.argmax(model.predict(x),axis=-1)\n",
    "\n",
    "\n",
    "def predict_prob(x):\n",
    "  return model.predict(x)\n",
    "\n",
    "def evaluate(x,y,batches=batchsize):\n",
    "  return model.evaluate(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eX7rpS2nPNQn"
   },
   "outputs": [],
   "source": [
    "history=train(35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U9nRPIh_H6Pq"
   },
   "outputs": [],
   "source": [
    "dic=history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YUVbf9rugNk-"
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('/content/google-drive/My Drive/deep_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gy4b81iazh-s"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "from matplotlib.pyplot import figure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JK2T4KzOzkTR"
   },
   "outputs": [],
   "source": [
    "figure(num=None, figsize=(12, 7), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.plot(dic[\"accuracy\"]);\n",
    "plt.plot(dic[\"val_accuracy\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gNbxtWqwz-1P"
   },
   "outputs": [],
   "source": [
    "figure(num=None, figsize=(12, 7), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.plot(dic[\"loss\"]);\n",
    "plt.plot(dic[\"val_loss\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "03O41uN_TWRK"
   },
   "outputs": [],
   "source": [
    "newIt = iter(val_batch)\n",
    "data =next(newIt)\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dRBfsQCmIm5B"
   },
   "outputs": [],
   "source": [
    "predict(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cVi9JP991gJK"
   },
   "outputs": [],
   "source": [
    "evaluate(data[0],data[1])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "inspectTfrecord2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
